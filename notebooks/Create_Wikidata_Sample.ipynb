{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fbcf6b4",
   "metadata": {},
   "source": [
    "# Create Sample Wikidata\n",
    "\n",
    "* Translate Stream Updater JSON to SPARQL UPDATE (INSERT/DELETE DATA) statements\n",
    "** To be used in testing of the stress test infrastructure and process\n",
    "** Saved as sparql-update.txt\n",
    "* Capture the earliest (first) triple for each deleted subject/predicate pair in a new file, deleted-triples.nt\n",
    "* Reverse the INSERT/DELETE sequence to completely restore a Wikidata RDF load\n",
    "* Transform the CSV data used in testing the query analysis infrastructure to N-triples \n",
    "** 3 files were provided with entities from the human, scholarly articles, taxon, gene and film subgraphs\n",
    "* Manually add the results from translating the 3 files above to the deleted-triples.nt file, to create wikidata-subset.nt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "157f2cac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T21:17:15.406847Z",
     "start_time": "2022-06-16T21:17:15.401990Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import queue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c76607",
   "metadata": {},
   "source": [
    "## Process the Steaming Updater JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "532e094e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T21:17:20.953944Z",
     "start_time": "2022-06-16T21:17:20.796016Z"
    }
   },
   "outputs": [],
   "source": [
    "# Take dump of Stream Updater data and convert to SPARQL INSERT/DELETE statements\n",
    "with open(\"wikidata_update_stream_6k_edits_20220531.ndjson\", \"r\") as update_data:\n",
    "    with open('sparql-update.txt', 'w') as sparql_update:\n",
    "        while True:\n",
    "            line = update_data.readline()  # Read an entry\n",
    "            if not line: \n",
    "                break\n",
    "            entry = json.loads(line)\n",
    "            operation = entry[\"operation\"]\n",
    "            if operation == \"reconcile\":   # Reconciles are not relevant at this time\n",
    "                continue\n",
    "            request = ''\n",
    "            if \"rdf_added_data\" in entry.keys():\n",
    "                request += \"INSERT DATA { \" + \\\n",
    "                    entry[\"rdf_added_data\"][\"data\"].replace(\"\\n\", \" \").replace(\"\\t\", \"\").strip() + \"}\\n\"\n",
    "            if \"rdf_deleted_data\" in entry.keys():\n",
    "                request += \"DELETE DATA { \" + \\\n",
    "                    entry[\"rdf_deleted_data\"][\"data\"].replace(\"\\n\", \" \").replace(\"\\t\", \"\").strip() + \"}\\n\"\n",
    "            if \"rdf_linked_data\" in entry.keys():\n",
    "                request += \"INSERT DATA { \" + \\\n",
    "                    entry[\"rdf_linked_data\"][\"data\"].replace(\"\\n\", \" \").replace(\"\\t\", \"\").strip() + \"}\\n\"\n",
    "            # Ignore rdf_unlinked_data\n",
    "            sparql_update.write(request)\n",
    "            # Note that operations with sequence_lengths different than 1 are not treated differently\n",
    "            # All information in the JSON output is written as complete triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2aa84701",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T21:18:21.048069Z",
     "start_time": "2022-06-16T21:18:20.964208Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add first occurrence of each \"deleted\" subj/predicate triple to an output file\n",
    "# May miss a few, unique triples if the object can be multi-valued\n",
    "triples = dict()\n",
    "with open('sparql-update.txt', 'r') as sparql_update:\n",
    "    while True:\n",
    "        line = sparql_update.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        if line.startswith(\"INSERT \"):   # Only processing DELETED triples\n",
    "            continue\n",
    "        del_data = line.split(\"{\")[1].split(\"}\")[0]\n",
    "        statements = del_data.split(\" . \")\n",
    "        for statement in statements:\n",
    "            subj = statement.split('<')[1].split(\">\")[0]\n",
    "            clauses = statement.split(' ; ')\n",
    "            first_clause = True\n",
    "            for clause in clauses:\n",
    "                if clause.endswith(\" .\"):\n",
    "                    clause = clause[:-2]\n",
    "                if ' a ' in clause:\n",
    "                    pred = '-a'\n",
    "                else:\n",
    "                    if first_clause:\n",
    "                        pred = clause.split('<')[2].split('>')[0]    # First clause has full subj-pred-obj\n",
    "                    else:\n",
    "                        pred = clause.split('<')[1].split('>')[0]    # Clause is only pred-obj\n",
    "                if subj+pred not in triples.keys():\n",
    "                    if first_clause:    \n",
    "                        triples[subj+pred] = f\"{clause.strip()} .\"\n",
    "                    else:\n",
    "                        triples[subj+pred] = f\"<{subj}> {clause.strip()} .\"\n",
    "                if first_clause:\n",
    "                    first_clause = False\n",
    "with open(\"deleted-triples.nt\", \"w\") as new:\n",
    "    for key, value in triples.items():\n",
    "        new.write(value + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f096ab6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T21:19:24.839615Z",
     "start_time": "2022-06-16T21:19:24.732780Z"
    }
   },
   "outputs": [],
   "source": [
    "# To account for re-adding any new triples or deleting any inserted ones\n",
    "# When operating with a complete dump of the Wikidata RDF\n",
    "# Process the Updater's INSERTs/DELETEs in reverse order, and also reverse the requests such that INSERTs become DELETEs and vice-versa\n",
    "lifo = queue.LifoQueue()\n",
    "with open('sparql-update.txt', 'r') as sparql_update:\n",
    "    while True:\n",
    "        line = sparql_update.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        if line.startswith(\"DELETE \"):\n",
    "            new_line = line.replace(\"DELETE DATA\", \"INSERT DATA\")\n",
    "        else:\n",
    "            new_line = line.replace(\"INSERT DATA\", \"DELETE DATA\")\n",
    "        lifo.put(new_line)\n",
    "with open(\"restore_wikidata.txt\", \"w\") as new:\n",
    "    while not lifo.empty():\n",
    "        new.write(lifo.get())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346e0b0c",
   "metadata": {},
   "source": [
    "# Process the Sample RDF Used for Query Analysis Code Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97456ed1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T21:20:22.724292Z",
     "start_time": "2022-06-16T21:20:22.685400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert CSV from the test infrastructure for query analyses, into triples\n",
    "for input_file in ('subgraphs', 'scholarly_articles', 'scholarly_articles_and_authors'):\n",
    "    with open(f'{input_file}.csv', newline='') as csvfile:\n",
    "        with open(f'{input_file}.nt', 'w') as wikidata:\n",
    "            reader = csv.DictReader(csvfile)\n",
    "            for row in reader:\n",
    "                wikidata.write(f\"{row['subject']} {row['predicate']} {row['object']} .\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dcb600",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
